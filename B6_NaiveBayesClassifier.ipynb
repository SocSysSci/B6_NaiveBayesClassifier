{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SocSysSci/B6_NaiveBayesClassifier/blob/main/B6_NaiveBayesClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGzMnP_TwNtI"
      },
      "source": [
        "# 1. 単純ベイズ分類器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgDSFoGlwYTg"
      },
      "source": [
        "### パッケージの読み込み\n",
        "\n",
        "ここではガウス分布の単純ベイズ分類器（GaussianNB）を利用。単純ベイズ分類器を含む機械学習パッケージ（scikit-learn）については資料を参照のこと。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQOohJf6jxTQ"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncxw2wH8wfdT"
      },
      "source": [
        "### 学習セットの用意\n",
        "\n",
        "学習セットの説明については資料を参照のこと。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKWvTl2ZwGko"
      },
      "source": [
        "X = np.array([[1, 0, 1, 1, 2, 1, 1, 0, 0],\n",
        "              [1, 2, 0, 1, 0, 0, 3, 3, 1],\n",
        "              [2, 0, 1, 0, 3, 1, 0, 2, 1]])\n",
        "y = np.array([1, 2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcj6mQi-wipz"
      },
      "source": [
        "### 単純ベイズ分類器の学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9J6b-YQwK2R"
      },
      "source": [
        "clf = GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIeRIgVbwmnD"
      },
      "source": [
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1wu9pekwoEO"
      },
      "source": [
        "clf.score(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Kg4k9SwtC5"
      },
      "source": [
        "### 学習済の分類器を用いた推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf35gel-wqmC"
      },
      "source": [
        "t = np.array([[1, 0, 1, 1, 0, 0, 1, 0, 0]])\n",
        "clf.predict(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev2uvf0CxCuI"
      },
      "source": [
        "# 2. テキストの分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foY5ec4TxGKr"
      },
      "source": [
        "### パッケージの読み込み\n",
        "\n",
        "CountVectorizerは単語の数を数えるパッケージで，これを利用してBoWベクトルを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ONmQIuw9oX"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6lxNTadxYiu"
      },
      "source": [
        "### 学習セットの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM5CWoYixTk2"
      },
      "source": [
        "s = ['今日 は とても 天気 が いい',\n",
        "     '今日 は 晴れ です',\n",
        "     '天気 が いい 日 は 晴れ です']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITHiuH_6xeCR"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(s)\n",
        "X = vectorizer.transform(s).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afh_WeoCxjTt"
      },
      "source": [
        "y = np.array([1, 2, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE8hSCLexpKm"
      },
      "source": [
        "### 単純ベイズ分類器の学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yatQza5cxlVu"
      },
      "source": [
        "clf = GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYnQZ8KJxvLm"
      },
      "source": [
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V3qf4SoxwSg"
      },
      "source": [
        "clf.score(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiUsBpksx1N0"
      },
      "source": [
        "### 学習済分類器を用いた推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcMfFJ1LxyVH"
      },
      "source": [
        "t = vectorizer.transform([\"明日 は 天気 が いい\"]).toarray()\n",
        "clf.predict(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbwnJngSyG1M"
      },
      "source": [
        "# 3. 長いテキストの分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq18U9vpypfF"
      },
      "source": [
        "### janome（形態素解析）のインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQcLg-onyDLF"
      },
      "source": [
        "!pip install janome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xu7tKVyuPn"
      },
      "source": [
        "### パッケージの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxWXVmRyTQ8"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from janome.tokenizer import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBNDNyBv0Ho8"
      },
      "source": [
        "### 学習用文書の読み込み\n",
        "まず，テキストファイルをアップロードします。\n",
        "続いて以下のセルを実行し，15つアップしたうち，12を学習用に，3つはテスト用にします。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# テキスト読み込み用の関数定義\n",
        "def file_load(file_name):\n",
        "  text = None\n",
        "  with open(file_name, \"r\") as f:\n",
        "    text = \"\\n\".join(f.readlines())\n",
        "  return text"
      ],
      "metadata": {
        "id": "JU5I2NIVbP4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG5RgXVdzAPg"
      },
      "source": [
        "file_list = [\n",
        "    # 夏目漱石\n",
        "    \"bot_content.txt\",\n",
        "    \"34ro_content.txt\",\n",
        "    \"kokoro_content.txt\",\n",
        "    \"sore_content.txt\",\n",
        "    \"meian_content.txt\",\n",
        "    # 芥川竜之介\n",
        "    \"jigokuhen_content.txt\",\n",
        "    \"kappa_content.txt\",\n",
        "    \"syuju_content.txt\",\n",
        "    # 太宰治\n",
        "    \"ningen_content.txt\",\n",
        "    \"shayou_content.txt\",\n",
        "    \"hamlet_content.txt\",\n",
        "    \"pandora_content.txt\"\n",
        "]\n",
        "text_list = []\n",
        "for file in file_list:\n",
        "  text_list.append(file_load(file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最初のテキスト（坊ちゃん）の最初の1000文字を表示\n",
        "text_list[0][0:1000]"
      ],
      "metadata": {
        "id": "QkdUVHEvehFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### クレンジング\n",
        "\n",
        "まずクレンジング用の関数を定義して，そのあとクレンジング"
      ],
      "metadata": {
        "id": "ZL-uJuz8ZPuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def cleansing(text):\n",
        "  clean_text = re.sub(\"\\s\", \"\", text)                     # 余分な空白（改行や字下げの空白）を除去\n",
        "  clean_text = clean_text.replace(\"<br/>\", \"\\n\")          # <br/>タグを改行に変換\n",
        "  clean_text = re.sub(r\"<rp>[^<]+</rp>\", \"\", clean_text)  # ルビの前後の括弧を除去\n",
        "  clean_text = re.sub(r\"<rt>[^<]+</rt>\", \"\", clean_text)  # ルビのテキストを除去\n",
        "  clean_text = re.sub(r\"<[^>]+>\", \"\", clean_text)         # それ以外のタグを除去\n",
        "  return clean_text"
      ],
      "metadata": {
        "id": "ZHaYgyasKzr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_list = []\n",
        "for text in text_list:\n",
        "  clean_text_list.append(cleansing(text))"
      ],
      "metadata": {
        "id": "ZA268qXmZUfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最初のテキストの最初の1000文字を表示\n",
        "clean_text_list[0][0:1000]"
      ],
      "metadata": {
        "id": "heGA_PMifLhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trj3cZTY0mAf"
      },
      "source": [
        "### 分かち書きにする"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 分かち書き用の関数定義\n",
        "def wakati_text(text, pos=[\"名詞\", \"動詞\"]):\n",
        "    tokenizer = Tokenizer()\n",
        "    doc = tokenizer.tokenize(text)\n",
        "    wakati = None\n",
        "    word_list = []\n",
        "    for token in doc:\n",
        "        p = token.part_of_speech.split(\",\")[0]\n",
        "        if p in pos:\n",
        "            word_list.append(token.base_form)\n",
        "    if 0 < len(word_list):\n",
        "        wakati = \" \".join(word_list)\n",
        "    return wakati"
      ],
      "metadata": {
        "id": "pqP9aNPpbVAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12個のテキストを分かち書きするのにすごく時間がかかるので，最初の1000文字だけ使います。"
      ],
      "metadata": {
        "id": "jSRJ8WIiSlot"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tmxkf010gIx"
      },
      "source": [
        "wakati_list = []\n",
        "for clean_text in clean_text_list:\n",
        "    wakati_list.append(wakati_text(clean_text[0:1000], [\"名詞\", \"動詞\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDaxnVgQ0kvj"
      },
      "source": [
        "# 最初のテキストデータの最初の1000文字を表示\n",
        "wakati_list[0][0:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHSXXwbO04jG"
      },
      "source": [
        "### BoWの計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an59JMIf0qhy"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(wakati_list)\n",
        "X = vectorizer.transform(wakati_list).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ_HA6Sv1LLh"
      },
      "source": [
        "### テキストごとのクラスを用意\n",
        "1：夏目漱石 2：芥川竜之介　3:太宰治"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAmqnjo1IXB"
      },
      "source": [
        "y = np.array([1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwH-ofzi1YGn"
      },
      "source": [
        "### 単純ベイズ分類器の学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqu7JhQf1VaZ"
      },
      "source": [
        "clf = GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuepiFw61d_Y"
      },
      "source": [
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Pew6s71fqN"
      },
      "source": [
        "clf.score(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG3MsZbd1la6"
      },
      "source": [
        "### テスト用文書の読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8KxX5Sq1hh4"
      },
      "source": [
        "test_file_list = [\"waganeko_content.txt\", \"kumo_content.txt\", \"melos_content.txt\"]\n",
        "test_text_list = []\n",
        "for file in test_file_list:\n",
        "    test_text_list.append(file_load(file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### クレンジング"
      ],
      "metadata": {
        "id": "GAjiMp5Mf0zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_clean_list = []\n",
        "for text in test_text_list:\n",
        "  test_clean_list.append(cleansing(text))"
      ],
      "metadata": {
        "id": "T4PtcXspf0Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbRfqLJW10Ei"
      },
      "source": [
        "### テスト用文書の分かち書き\n",
        "\n",
        "最初の1000文字だけ使っています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGfKYuLZ1zIo"
      },
      "source": [
        "test_wakati_list = []\n",
        "for clean_text in test_clean_list:\n",
        "  test_wakati_list.append(wakati_text(clean_text[0:1000], [\"名詞\", \"動詞\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj1czoot2SMZ"
      },
      "source": [
        "test_wakati_list[0][0:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z27MFGOI2sLf"
      },
      "source": [
        "### BoWの計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B57Ij0hq2UhB"
      },
      "source": [
        "T = vectorizer.transform(test_wakati_list).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0KEKN8z3Dco"
      },
      "source": [
        "### 学習済の分類器を用いて推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_sTqumP3AbA"
      },
      "source": [
        "clf.predict(T)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}